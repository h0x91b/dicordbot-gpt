import { Message, TextChannel } from "discord.js";
import { fetchMessageHistory } from "../services/discord";
import {
  getChatCompletion as getChatCompletionClaude,
  AnthropicModel,
} from "../services/anthropic";
import { getChatCompletion, OpenAIModel } from "../services/openai";
import { tempFile } from "../utils";
import * as utils from "util";
import { ChatCompletionRequestMessage } from "openai";
import { buildCoderPrompt } from "../prompts/coder";
import fetch from "node-fetch"; // –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º fetch –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ DuckDuckGo

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ DuckDuckGo
async function searchDuckDuckGo(query: string): Promise<string[]> {
  const url = `https://api.duckduckgo.com/?q=${encodeURIComponent(query)}&format=json`;
  const response = await fetch(url);
  if (!response.ok) throw new Error("–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –ø–æ–∏—Å–∫ –≤ DuckDuckGo");
  
  const data = await response.json();
  return data.RelatedTopics.map((topic: any) => topic.Text).filter(Boolean); // –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–∞—Å—Å–∏–≤ —Å–Ω–∏–ø–ø–µ—Ç–æ–≤
}

export async function coderChatbotHandler(msg: Message) {
  msg.react("üëÄ");
  let messages = await fetchMessageHistory(msg);

  const system = await buildCoderPrompt(msg);

  messages.unshift({
    role: "system",
    content: [{ type: "text", text: system }],
  });

  const opts = {};
  let respMessage = "";
  let price = 0;
  const useClaude = true;
  let model: string = "claude-3-5-sonnet-20241022" as AnthropicModel;
  if (!useClaude) model = OpenAIModel.GPT_4O_2024_08_06;

  // –ü–æ–ª—É—á–∞–µ–º –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
  const userQuery = msg.content.replace("!coder ", ""); // –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –∫–æ–º–∞–Ω–¥–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å "!coder "

  // –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ –≤ DuckDuckGo
  const searchResults = await searchDuckDuckGo(userQuery);
  const searchContext = searchResults.join("\n"); // –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Å—Ç—Ä–æ–∫—É

  for (let i = 0; i < 10; i++) {
    console.log(
      "coderChatbotHandler",
      utils.inspect(messages, false, null, true)
    );

    // –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∫ —Å–æ–æ–±—â–µ–Ω–∏—è–º
    messages.push({
      role: "user",
      content: searchContext, // –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ DuckDuckGo
    });

    let r = useClaude
      ? await getChatCompletionClaude(model as AnthropicModel, messages, opts)
      : await getChatCompletion(
          model,
          messages as unknown as ChatCompletionRequestMessage[],
          opts
        );

    console.log("r", r);
    if (useClaude && "content" in r && Array.isArray(r.content)) {
      const text = r.content[0]?.text || ".";
      respMessage += text;
      console.log("Claude response", text);
      price += r.price;
    } else if (!useClaude && "content" in r) {
      respMessage += r.content || "";
      price += "price" in r ? r.price : 0;
    }

    if (useClaude && "stop_reason" in r && r.stop_reason === "end_turn") {
      console.log("Price", price);
      respMessage = `[${price.toFixed(4)}$ ${model}]\n` + respMessage;
      if (respMessage.length > 2000) {
        const t = await tempFile(respMessage);
        return await msg.reply({
          content: "Message too long, sending as file",
          files: [t],
        });
      }
      return await msg.reply({
        content: respMessage,
      });
    } else if (!useClaude && "content" in r) {
      console.log("Price", price);
      respMessage = `[${price.toFixed(4)}$ ${model}]\n` + respMessage;
      if (respMessage.length > 2000) {
        const t = await tempFile(respMessage);
        return await msg.reply({
          content:
            `[${price.toFixed(4)}$ ${model}]\n` +
            "Message too long, sending as file",
          files: [t],
        });
      }
      return await msg.reply({
        content: respMessage,
      });
    }
  }
}
