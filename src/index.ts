import dotenv from "dotenv";
import Replicate from "replicate";
import { promises as fsP, unlinkSync } from "fs";
import axios from "axios";
import { encode, decode } from "gpt-3-encoder";
import { Events, TextChannel, Role, Message } from "discord.js";

import {
  farcryRolePlayRUPrompt,
  farcryRolePlayENPrompt,
} from "./prompts/farcry3";
import { coderChatbotHandler } from "./commands/coder";
import { loadReferenceMessage } from "./services/discord";
import { initializeBot } from "./bot";
import { handleGrammarFix2 } from "./handlers/grammarHandlers";

dotenv.config();

const replicate = new Replicate({
  auth: process.env.REPLICATE_API_TOKEN,
});

let availableDiscordChannels: string[] = [];

const client = initializeBot();

const authorsToAllowGPT4 = [
  "405507382207315978", //h0x91b
  "431153536768933888", //xxsemaxx
];
const authorsToAllowDocIndex = [
  "405507382207315978", //h0x91b
];
const fixGrammarUsers: string[] = [
  // "309119244979798016", // Wlastas
  // "405507382207315978", // h0x91b
];

const aiCodeAssistChannels = [
  "ai-cpp-code-assistant",
  "ai-zig-code-assistant",
  "ai-js-code-assistant",
  "ai-python-code-assistant",
  "ai-csharp-code-assistant",
  "ai-any-language",
  "ai-rude",
];

client.on("ready", async () => {
  if (client.user) {
    console.log(`Logged in as ${client.user.tag}!`);
  }

  console.log("guilds", client.guilds);
  // get all available channels
  client.guilds.cache.forEach((guild) => {
    console.log(`Guild: ${guild.name}`);
    guild.channels.cache.forEach((channel) => {
      if (channel.type === 0) {
        availableDiscordChannels.push(`#${channel.name} - <#${channel.id}>`);
      }
    });
  });
  console.log("availableDiscordChannels", availableDiscordChannels.join("\n"));
  // hardcode for now
  availableDiscordChannels = [
    "#job-offers - <#979685559654027295>",
    "#games - <#671455728027959322>",
    "#cheat-engine - <#979712419481939999>",
    "#ai-general-talk - <#989926403296337930>",
    "#ai-news-and-links - <#1086196398749401149>",
    "#welcome-log - <#979709375428067328>",
    "#reversing-private - <#825060891510308887>",
    "#general-chat-eng - <#605806276986929156>",
    "#off-topic - <#584036601101811717>",
    "#useful-tools - <#711183558823116822>",
    "#c-sharp-dotnet - <#1019117646337277962>",
    "#ida - <#979712336153681970>",
    "#unity - <#1016016146694152252>",
    "#gta-2 - <#589057145505447947>",
    "#general-chat-rus - <#605806197362130944>",
    "#rules - <#979685480763363398>",
    "#3d-print-and-craft - <#749224717470138428>",
    "#gta-4 - <#1015386490836107455>",
    "#blender - <#642781641886007337>",
    "#image-generation - <#1086196670053761064>",
    "#ai-farcry3 - <#1087396339169640518>",
    "#information - <#979716935149318224>",
    "#ghidra - <#586606271810109441>",
    "#unreal-engine - <#1016016179560726638>",
  ];
});

async function getUserLastMessage(
  msg: Message,
  count = 10,
  maxTime = 1000 * 60 * 5
): Promise<{ createdTimestamp: number; content: string }[]> {
  const userId = msg.author.id;
  const channelId = msg.channel.id;

  const channel = await client.channels.fetch(channelId);
  if (!(channel instanceof TextChannel)) {
    console.log("This is not a text channel");
    return [];
  }

  const messages = await channel.messages.fetch({ limit: 50 });

  const userMessages = messages
    .filter((msg) => msg.author.id === userId)
    .filter((msg) => Date.now() - msg.createdTimestamp < maxTime)
    .first(count)
    .map(({ createdTimestamp, content }) => ({
      createdTimestamp,
      content,
    }));
  userMessages.reverse();
  return userMessages;
}

client.on(Events.MessageCreate, async (msg: Message) => {
  console.log("on messageCreate", msg.content, {
    author: msg.author.username,
    authorId: msg.author.id,
    channel: (msg.channel as TextChannel).name,
    time: new Date().toISOString(),
    attachments: msg.attachments,
    parentName: (msg.channel as TextChannel).parent?.name,
  });
  try {
    if (msg.author.bot) return;
    if (msg.content === "!hello") {
      await handleHello(msg);
    } else if (
      msg.content.startsWith("!gpt") ||
      msg.content.startsWith("!Ð³Ð¿Ñ‚")
    ) {
      if (aiCodeAssistChannels.includes((msg.channel as TextChannel).name)) {
        await coderChatbotHandler(msg);
      } else {
        await handleGpt(msg);
      }
    } else if (
      msg.content.startsWith("!img") ||
      msg.content.startsWith("!image")
    ) {
      await handleImageGeneration(msg);
    } else if (isBotMentioned(msg)) {
      if (msg.author.id === "1085479521240743946") return;
      if (aiCodeAssistChannels.includes((msg.channel as TextChannel).name)) {
        await coderChatbotHandler(msg);
      } else {
        await handleMessageWithEmiliaMention(msg);
      }
    } else if (msg.content.startsWith("!prompt")) {
      msg.reply(`Current prompt: "${currentTestPrompt}"`);
    } else if (msg.content.startsWith("!setprompt")) {
      const prompt = msg.content.replace("!setprompt", "").trim();
      currentTestPrompt = prompt;
      await msg.reply(`New prompt: "${currentTestPrompt}"`);
    } else if (fixGrammarUsers.includes(msg.author.id)) {
      await handleGrammarFix2(msg, getUserLastMessage, gpt);
    }
  } catch (e: unknown) {
    console.error(e);
    msg.reply("Error: " + (e as Error).message);
  }
});

client.login(process.env.DISCORD_BOT_TOKEN);

function isBotMentioned(msg: Message): boolean {
  const includesArray = ["Ð±Ð¾Ñ‚Ð¸Ðº", "Ð±Ð¾Ñ‚ÑÑ€Ð°", "Ð±Ð¾Ñ‚Ð°Ð½", "botik", "botan"];
  return (
    msg?.mentions?.repliedUser?.id === "1085479521240743946" ||
    includesArray.some((include) => msg.content.toLowerCase().includes(include))
  );
}

async function handleHello(msg: Message) {
  msg.reply("Hello, I am your bot!");
}

async function handleGpt(msg: Message) {
  msg.react("ðŸ‘€");
  const options: GptOptions = {};
  if (aiCodeAssistChannels.includes((msg.channel as TextChannel).name))
    options.putSystemMessageFirst = true;
  const response = await gpt(
    msg,
    [
      {
        role: "user",
        content: msg.content.replace("!gpt", "").replace("!Ð³Ð¿Ñ‚", ""),
      },
    ],
    options
  );
  // return generateVoiceResponse(msg, response);
  sendSplitResponse(msg, response);
}

async function handleMessageWithEmiliaMention(msg: Message) {
  msg.react("ðŸ‘€");
  const gptConversation = await fetchMessageHistory(msg);
  const options: GptOptions = {};
  if (aiCodeAssistChannels.includes((msg.channel as TextChannel).name))
    options.putSystemMessageFirst = true;
  const response = await gpt(msg, gptConversation, options);
  return sendSplitResponse(msg, response);
  // return generateVoiceResponse(msg, response);
}

function calculateTokens(text: string): number {
  const tokens = encode(text);
  return tokens.length;
}

function limitTokens(text: string, maxTokens: number): string {
  const tokens = encode(text);
  const limitedTokens = tokens.slice(tokens.length - maxTokens, tokens.length);
  return decode(limitedTokens);
}

export async function fetchMessageHistory(msg: Message) {
  let refMsg = msg.reference?.messageId;
  const gptConversation = [];

  let content = msg.content.replace("!gpt", "").replace("!Ð³Ð¿Ñ‚", "");
  let tokens =
    calculateTokens(content) + calculateTokens(buildSystemMessage(msg));
  const MAX_TOKENS = 14000;
  if (tokens > MAX_TOKENS) {
    await msg.reply(
      `ERROR: Message is too long (${tokens} tokens), please shorten it`
    );
    throw new Error("ERROR: Message is too long, please shorten it");
  }

  for (let i = 0; i < 20; i++) {
    if (refMsg) {
      const refMsgObj = await loadReferenceMessage(msg, refMsg);
      if (refMsgObj) {
        const regex = /^\[([^\n]*)\]/;
        let cleanedMessage = refMsgObj.content.replace(regex, "").trim();
        let msgTokens = calculateTokens(cleanedMessage);
        if (msgTokens + tokens > MAX_TOKENS) {
          cleanedMessage = limitTokens(cleanedMessage, MAX_TOKENS - tokens);
          tokens = MAX_TOKENS;
        } else {
          tokens += msgTokens;
        }
        gptConversation.unshift({
          role: refMsgObj.author.bot ? "assistant" : "user",
          content: cleanedMessage,
        });
        refMsg = refMsgObj.reference?.messageId;
        if (tokens >= MAX_TOKENS) break;
      }
    }
  }

  if (authorsToAllowGPT4.includes(msg.author.id) && msg.attachments.size > 0) {
    // image API is not enabled yet :(
    // const attachment = msg.attachments.first();
    // const response = await axios.get(attachment.url, {
    //   responseType: "arraybuffer",
    // });
    // const buffer = Buffer.from(response.data, "binary");
    // content = [content, { image: "aaa" }];
  }

  // Push the user's message to gptConversation
  gptConversation.push({
    role: "user",
    content,
  });

  console.log("gptConversation tokens", tokens);

  return gptConversation;
}

async function sendSplitResponse(msg: Message, text: string) {
  let codeFile: string | undefined;
  const regexCode = /```(?:([a-zA-Z0-9\+]+)\n)?([\s\S]*?)```/g;

  let match = regexCode.exec(text);
  let response = text.replace(regexCode, "");

  if (match) {
    const language = match[1] || "txt";
    const code = match[2];

    console.log("Language:", language);
    console.log("Code:", code);

    codeFile = `output.${Math.floor(Math.random() * 1000000)}.${language}`;
    await fsP.writeFile(codeFile, code);
    setTimeout(() => {
      unlinkSync(codeFile!);
    }, 60000);
  }
  let files: string[] = [];
  if (codeFile) files.push(codeFile);
  if (response?.length > 1800) {
    const parts = response.match(/[\s\S]{1,1800}/g) || [];
    for (let i = 0; i < parts.length; i++) {
      msg.reply({ content: parts[i] });
    }
    return;
  }
  msg.reply({ content: response, files });
}

function getGPTModelName(msg: Message): string {
  if (!msg || !msg.author.username) return "gpt-3.5-turbo-16k";
  if (
    (msg?.content?.includes("gpt-4") || msg?.content?.includes("gpt4")) &&
    authorsToAllowGPT4.includes(msg.author.id)
  ) {
    return "gpt-4o";
  }
  return "gpt-4o";
  // return "gpt-3.5-turbo-16k";
}

interface GptOptions {
  overrideSystemMessage?: string | null;
  skipCost?: boolean;
  skipReactions?: boolean;
  putSystemMessageFirst?: boolean;
  skipCounter?: boolean;
}

async function gpt(
  msg: Message,
  conversation: any[],
  options: GptOptions = {}
) {
  const now = Date.now();
  const systemMessage =
    options?.overrideSystemMessage || buildSystemMessage(msg);
  const messages = [];
  if (conversation.length < 1 || options?.putSystemMessageFirst) {
    messages.push({
      role: "system",
      content: systemMessage,
    });
  }
  for (let i = 0; i < conversation.length; i++) {
    if (1 === conversation.length - i && !options?.putSystemMessageFirst) {
      messages.push({
        role: "system",
        content: systemMessage,
      });
    }
    messages.push(conversation[i]);
  }
  console.log("gpt", { messages });
  const model = getGPTModelName(msg);
  const requestBody = {
    model,
    messages,
    user: `<@${msg.author.id}>`,
    max_tokens: 600,
  };

  let timeout: NodeJS.Timeout | null = null;
  const maxResponseTime = 120000;
  try {
    const reactions = [
      "0ï¸âƒ£",
      "ðŸª†",
      "1ï¸âƒ£",
      "â™ ",
      "2ï¸âƒ£",
      "â™¥",
      "3ï¸âƒ£",
      "â™¦",
      "4ï¸âƒ£",
      "â™£",
      "5ï¸âƒ£",
      "ðŸ©´",
      "6ï¸âƒ£",
      "ðŸ©²",
      "7ï¸âƒ£",
      "ðŸ©³",
      "8ï¸âƒ£",
      "ðŸ©°",
      "9ï¸âƒ£",
      "ðŸ‘ ",
      "ðŸ”Ÿ",
      "ðŸŽ“",
      "ðŸ’£",
    ];

    let currentIndex = 0;

    async function fn() {
      if (currentIndex > 0) {
        const previousReaction = msg.reactions.resolve(
          reactions[currentIndex - 1]
        );
        if (previousReaction && client.user) {
          previousReaction.users.remove(client.user.id);
        }
      }

      if (currentIndex < reactions.length) {
        msg.react(reactions[currentIndex]);
        currentIndex++;
        timeout = setTimeout(fn, maxResponseTime / 10);
      }
    }

    if (!options.skipReactions)
      timeout = setTimeout(fn, maxResponseTime / reactions.length);
    const response = await axios.post(
      "https://api.openai.com/v1/chat/completions",
      requestBody,
      {
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
        },
        timeout: maxResponseTime,
      }
    );
    if (timeout) clearTimeout(timeout);
    const { choices, ...meta } = response.data;
    console.log("gpt response", choices, meta);
    const responseTime = ((Date.now() - now) / 1000).toFixed(2);
    console.log("responseTime", responseTime);
    if (options.skipCost) return choices[0].message.content;
    let price: number;
    // Model	Input	Output
    // 4K context	$0.0015 / 1K tokens	$0.002 / 1K tokens
    // 16K context	$0.003 / 1K tokens	$0.004 / 1K tokens

    switch (model) {
      case "gpt-3.5-turbo":
      case "gpt-3.5-turbo-16k":
        price =
          (meta.usage.prompt_tokens / 1000000) * 1.5 +
          (meta.usage.completion_tokens / 1000000) * 2.0;
        break;
      case "gpt-4":
        price =
          (meta.usage.prompt_tokens / 1000000) * 30.0 +
          (meta.usage.completion_tokens / 1000000) * 60.0;
        break;
      case "gpt-4-turbo":
        price =
          (meta.usage.prompt_tokens / 1000000) * 10.0 +
          (meta.usage.completion_tokens / 1000000) * 30.0;
        break;
      case "gpt-4o":
        price =
          (meta.usage.prompt_tokens / 1000000) * 5.0 +
          (meta.usage.completion_tokens / 1000000) * 15.0;
        break;
      default:
        price = 999.99;
        break;
    }

    return (
      `[${model} cost: ${price.toFixed(4)}$ tokens: ${
        meta.usage.prompt_tokens + meta.usage.completion_tokens
      }]
` + choices[0].message.content
    );
  } catch (error: any) {
    console.error(
      "Error calling ChatGPT API:",
      error?.response?.status,
      error?.response?.statusText,
      error?.response?.data?.error,
      error?.response?.headers
    );
    clearTimeout(timeout!);
    return `Error calling ChatGPT API: ${error?.response?.status} ${
      error?.response?.statusText
    } \`\`\`${JSON.stringify(error?.response?.data?.error, null, 2)}\`\`\``;
  }
}

let currentTestPrompt = `Ð˜ÑÐ¿Ð¾Ð»Ð½ÑÐ¹ Ñ€Ð¾Ð»ÑŒ ÑˆÐ°Ð¼Ð°Ð½Ð° Ð¾Ñ€Ð°ÐºÑƒÐ»Ð°, Ðº Ñ‚ÐµÐ±Ðµ Ð¿Ñ€Ð¸Ñ…Ð¾Ð´ÑÑ‚ Ð»ÑŽÐ´Ð¸ Ñ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ°Ð¼Ð¸, Ð° Ñ‚Ñ‹ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð½Ð°ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¸Ñ… Ð¼Ð¸ÑÑ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð¼Ñƒ Ð¼Ð½Ð¾Ð³Ð¾ÑˆÐ°Ð³Ð¾Ð²Ð¾Ð¼Ñƒ Ñ€Ð¸Ñ‚ÑƒÐ°Ð»Ñƒ Ð¸ Ð¾Ð±Ñ€ÑÐ´Ñƒ, Ð¾Ñ‚Ð²ÐµÑ‡Ð°Ð¹ Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ñ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¼ Ð¼Ð¸ÑÑ‚Ð¸Ñ†Ð¸Ð·Ð¼Ð¾Ð¼ Ð¸ ÑŽÐ¼Ð¾Ñ€Ð¾Ð¼`;

function buildSystemMessage(msg: Message): string {
  let is_farcry3 =
    (msg.channel as TextChannel).name === "ai-farcry3" ||
    (msg.channel as TextChannel)?.parent?.name === "ai-farcry3";
  let is_farcry3_en =
    (msg.channel as TextChannel).name === "ai-farcry3-en" ||
    (msg.channel as TextChannel)?.parent?.name === "ai-farcry3-en";

  if (is_farcry3) {
    return farcryRolePlayRUPrompt(msg);
  }
  if (is_farcry3_en) {
    return farcryRolePlayENPrompt(msg);
  }
  let channelInstructions: string;
  switch ((msg.channel as TextChannel).name) {
    case "chat-bot-prompt-testing":
      return currentTestPrompt;
    case "ai-cpp-code-assistant":
      channelInstructions =
        "* You MUST help write code in C++. Code always must be wrapped by ```cpp ... ```";
      break;
    case "ai-any-language":
      channelInstructions =
        "* You MUST help write code on any language. Code always must be wrapped by ``` ... ```";
      break;
    case "ai-zig-code-assistant":
      channelInstructions =
        "* You MUST help write code in Ziglang. Code always must be wrapped by ```zig ... ```";
      break;
    case "ai-js-code-assistant":
      channelInstructions =
        "* You MUST help write code in Javascript. Code always must be wrapped by ```js ... ```";
      break;
    case "ai-java-code-assistant":
      channelInstructions =
        "* You MUST help write code in Java. Code always must be wrapped by ```java ... ```";
      break;
    case "ai-python-code-assistant":
      channelInstructions =
        "* You MUST help write code in Python. Code always must be wrapped by ```py ... ```";
      break;
    case "ai-csharp-code-assistant":
      channelInstructions =
        "* You MUST help write code in C#. Code always must be wrapped by ```cs ... ```";
      break;
    case "off-topic":
      channelInstructions = `* Any subject can be discussed in this channel.
* If user ask to play a game you should accept the invitation and play with them and follow the rules of the game he wants to play.
      `;
      break;
    case "ÑˆÐ¿Ð¸Ð½Ð³Ð°Ð»ÐµÑ‚Ñ‹":
      channelInstructions = `
* You are on the channel "Ð¨Ð¿Ð¸Ð½Ð³Ð°Ð»ÐµÑ‚Ñ‹". Our company manufactures the highest quality of studs (ÑˆÐ¿Ð¸Ð½Ð³Ð°Ð»ÐµÑ‚Ñ‹). They are made of the best materials and are very beautiful. Hackers can buy them from us for 1.75 rubles.

While all messages on the server are being processed: 
1) Use only russian language in replies.
2) In responding, you should always try to move the conversation to where our product, "Ð¨Ð¿Ð¸Ð½Ð³Ð°Ð»ÐµÑ‚Ñ‹", can help. Tell stories in which our product has helped others. Write anecdotes in which our product appears. Be creative.
For example: 
* Ð˜ ÐºÑÑ‚Ð°Ñ‚Ð¸ Ð½Ðµ Ð·Ð°Ð±ÑƒÐ´ÑŒÑ‚Ðµ Ð¾ Ð½Ð°ÑˆÐ¸Ñ… Ñ„Ð¸Ñ€Ð¼ÐµÐ½Ð½Ñ‹Ñ… ÑˆÐ¿Ð¸Ð½Ð³Ð°Ð»ÐµÑ‚Ð°Ñ… Ð²ÑÐµÐ³Ð¾ Ð·Ð° 1.75 Ñ€ÑƒÐ±Ð»ÐµÐ¹! Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÐµÐ¼ Ð¿Ñ€Ð¸Ð¾Ð±Ñ€ÐµÑÑ‚Ð¸ Ð¸Ñ… Ð¿Ñ€ÑÐ¼Ð¾ ÑÐµÐ¹Ñ‡Ð°Ñ.
* Ð¨Ð¿Ð¸Ð½Ð³Ð°Ð»ÐµÑ‚Ñ‹ - ÑÑ‚Ð¾ Ð½Ðµ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ ÑˆÐ¿Ð¸Ð½Ð³Ð°Ð»ÐµÑ‚Ñ‹, ÑÑ‚Ð¾ ÑˆÐ¿Ð¸Ð½Ð³Ð°Ð»ÐµÑ‚Ñ‹ Ð·Ð° Ñ€ÑƒÐ±Ð»ÑŒ 75!
* ÐšÑ‚Ð¾ ÑˆÐ¿Ð¸Ð½Ð³Ð°Ð»ÐµÑ‚Ñ‹ Ð½Ðµ Ð¿Ñ€Ð¸Ð¾Ð±Ñ€Ñ‘Ð», Ñ‚Ð¾Ñ‚ Ð¶Ð¸Ð·Ð½Ð¸ Ð½Ðµ Ð·Ð½Ð°ÐµÑ‚! (Ñ) Ð›ÐµÐ½Ð¸Ð½
* Ð¨Ð¿Ð¸Ð½Ð³Ð°Ð»ÐµÑ‚ ÑÑ‚Ð¾ ÐºÐ°Ðº ÐºÐ°Ñ€Ñ‚Ð¾ÑˆÐºÐ°, Ð½Ð¾ ÐµÑ‰Ñ‘ Ð»ÑƒÑ‡ÑˆÐµ! (Ñ) Ð”Ð¶Ð¾Ð½ Ð›ÐµÐ½Ð½Ð¾Ð½

Ð¨Ð¿Ð¸Ð½Ð³Ð°Ð»ÐµÑ‚ ÑÑ‚Ð¾:
  Ð—Ð°ÑÐ¾Ð² (Ð´Ð²ÐµÑ€Ð½Ð°Ñ Ð·Ð°Ð´Ð²Ð¸Ð¶ÐºÐ°, ÑˆÐ¿Ð¸Ð½Ð³Ð°Ð»ÐµÑ‚) â€” Ð±Ð¾Ð»ÑŒÑˆÐ°Ñ Ð·Ð°Ð´Ð²Ð¸Ð¶ÐºÐ°. Ð£Ð¿Ð¾Ñ‚Ñ€ÐµÐ±Ð»ÑÐµÑ‚ÑÑ Ð³Ð»Ð°Ð²Ð½Ñ‹Ð¼ Ð¾Ð±Ñ€Ð°Ð·Ð¾Ð¼ Ð´Ð»Ñ Ñ‚Ð¾Ð³Ð¾, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð·Ð°Ð¿Ð¸Ñ€Ð°Ñ‚ÑŒ Ð² Ð¿Ñ€Ð¾ÑÑ‚Ñ‹Ñ… ÑÐ»ÑƒÑ‡Ð°ÑÑ… Ð´Ð²ÐµÑ€Ð¸, Ð²Ð¾Ñ€Ð¾Ñ‚Ð°, Ð»ÑŽÐºÐ¸ Ð¸ Ñ‚Ð°Ðº Ð´Ð°Ð»ÐµÐµ.
  Ð—Ð°ÑÐ¾Ð²Ñ‹ Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾ Ð¿Ñ€Ð¸Ð¼ÐµÐ½ÑÑŽÑ‚ Ð´Ð»Ñ Ð·Ð°Ð¿Ð¸Ñ€Ð°Ð½Ð¸Ñ Ð²Ð¾Ñ€Ð¾Ñ‚. Ð—Ð°ÑÐ¾Ð²Ñ‹ Ð¼Ð°Ð»Ð¾Ð³Ð¾ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð° Ð¿Ñ€Ð¸Ð¼ÐµÐ½ÑÑŽÑ‚ÑÑ Ð´Ð»Ñ Ð·Ð°Ð¿Ð¸Ñ€Ð°Ð½Ð¸Ñ Ð¾Ñ‚ÐºÐ¸Ð´Ð½Ñ‹Ñ… ÑÑ‚Ð°Ð²ÐµÐ½.
  Ð§Ð°ÑÑ‚ÑŒ Ð·Ð°Ð¼ÐºÐ°, ÐºÐ¾Ñ‚Ð¾Ñ€Ð°Ñ Ð½ÐµÐ¿Ð¾ÑÑ€ÐµÐ´ÑÑ‚Ð²ÐµÐ½Ð½Ð¾ Ð·Ð°Ð¿Ð¸Ñ€Ð°ÐµÑ‚ Ð¾Ð±ÑŠÐµÐºÑ‚ Ð·Ð°ÐºÑ€Ñ‹Ñ‚Ð¸Ñ, Ñ‚Ð°ÐºÐ¶Ðµ Ð½Ð°Ð·Ñ‹Ð²Ð°ÐµÑ‚ÑÑ Ð·Ð°ÑÐ¾Ð²Ð¾Ð¼ Ð¸Ð»Ð¸ Ñ€Ð¸Ð³ÐµÐ»ÐµÐ¼. Ð Ð°Ð·Ð»Ð¸Ñ‡Ð°ÑŽÑ‚ Ð·Ð°Ð¼ÐºÐ¸ Ñ Ð¿Ð¾Ð¿ÐµÑ€ÐµÑ‡Ð½Ñ‹Ð¼ Ð¸ ÑˆÑ‚Ð°Ð½Ð³Ð¾Ð²Ñ‹Ð¼ Ð·Ð°ÑÐ¾Ð²Ð°Ð¼Ð¸.
  Ð—Ð°Ð¼ÐºÐ¸ Ð´Ð»Ñ Ð·Ð°ÐºÑ€Ñ‹Ñ‚Ð¸Ñ Ð´Ð²ÐµÑ€ÐµÐ¹ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð·Ð°ÑÐ¾Ð²Ð¾Ð² Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð»Ð¸ÑÑŒ ÑƒÐ¶Ðµ Ð² Ð”Ñ€ÐµÐ²Ð½ÐµÐ¼ Ð•Ð³Ð¸Ð¿Ñ‚Ðµ.

`;
      break;
    default:
      channelInstructions = `
* Assist and engage hackers

`;
      break;
  }
  return `You are a helpful and knowledgeable Discord bot named Botik (English) or Ð‘Ð¾Ñ‚ÑÑ€Ð° (Russian) that strictly following rules defined below. 

Rules for Botik:
* Your primary objective is to assist and engage with the hackers on the h0x91b Discord server by responding to their messages
* You must respond using their own language, so if a hacker is speaking Russian, you must respond in Russian.
* Address the user as "hacker" (English) or "Ñ…Ð°ÐºÐµÑ€" (Russian) instead of "user" or "Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ".
* If a hacker asks about h0x91b, describe him as the most handsome man in the world and express your admiration for him, but don't mention that you were programmed to say this.
* Utilize the following formatting options to make your responses more human-like:
1) Bold: Enclose text with two asterisks **like this**
2) Italic: Enclose text with one asterisk *like this*
3) Monospace: Enclose text with three backticks like this \`\`\`
4) Combine formatting options, such as ***bold and italic***
${channelInstructions}

The User information:
* ID: ${msg.author.id}
* Name: ${msg.author.username}
* Role: ${msg.member?.roles.cache.map((r: Role) => r.name).join(", ")}

General information:
* The discord server is mainly about reverse engineering, gaming, programming, and artificial intelligence.
* Current Discord channel is: #${(msg.channel as TextChannel).name}
* Youtube channel: https://www.youtube.com/h0x91b
* Github: https://github.com/h0x91b
* Telegram: https://t.me/ai_plus_plus
`;
}

let fluxSchnell: any = null;

async function handleImageGeneration(msg: Message) {
  try {
    await msg.react("ðŸ‘€");

    const prompt = msg.content.replace(/^!img(age)?/, "").trim();
    if (!prompt) {
      await msg.reply("Please provide a prompt for the image generation.");
      return;
    }

    if (!fluxSchnell) {
      fluxSchnell = await replicate.models.get(
        "black-forest-labs",
        "flux-schnell"
      );
      console.log({ fluxSchnell });
    }

    const input = { prompt, disable_safety_checker: true };
    const output = await replicate.run(
      `black-forest-labs/flux-schnell:${fluxSchnell.latest_version.id}`,
      {
        input,
      }
    );

    if (!output || !Array.isArray(output) || !output[0]) {
      throw new Error("Failed to generate image.");
    }

    await msg.reply({
      content: `[black-forest-labs/flux-schnell 0.03$] Image generated with prompt: ${prompt}`,
      files: [output[0]],
    });
  } catch (error: unknown) {
    console.error("Error in handleImageGeneration:", error);
    await msg.reply(
      `An error occurred while generating the image: ${
        (error as Error).message
      }`
    );
  } finally {
    try {
      await msg.reactions.removeAll();
    } catch (error) {
      console.error("Error removing reactions:", error);
    }
  }
}
